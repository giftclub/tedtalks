{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rows completed\n",
      "100 rows completed\n",
      "200 rows completed\n",
      "300 rows completed\n",
      "400 rows completed\n",
      "500 rows completed\n",
      "600 rows completed\n",
      "700 rows completed\n",
      "800 rows completed\n",
      "900 rows completed\n",
      "1000 rows completed\n",
      "1100 rows completed\n",
      "1200 rows completed\n",
      "1300 rows completed\n",
      "1400 rows completed\n",
      "1500 rows completed\n",
      "1600 rows completed\n",
      "1700 rows completed\n",
      "1800 rows completed\n",
      "1900 rows completed\n",
      "2000 rows completed\n",
      "2100 rows completed\n",
      "2200 rows completed\n",
      "0 rows completed\n",
      "100 rows completed\n",
      "200 rows completed\n",
      "300 rows completed\n",
      "400 rows completed\n",
      "500 rows completed\n",
      "600 rows completed\n",
      "700 rows completed\n",
      "800 rows completed\n",
      "900 rows completed\n",
      "1000 rows completed\n",
      "1100 rows completed\n",
      "1200 rows completed\n",
      "1300 rows completed\n",
      "1400 rows completed\n",
      "1500 rows completed\n",
      "1600 rows completed\n",
      "1700 rows completed\n",
      "1800 rows completed\n",
      "1900 rows completed\n",
      "2000 rows completed\n",
      "2100 rows completed\n",
      "2200 rows completed\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "import string\n",
    "from stop_words import get_stop_words\n",
    "\n",
    "\n",
    "# Load descriptions and titles\n",
    "colnames = ['title', 'views' , 'descr']\n",
    "data = pandas.read_csv('./data/descriptions-2.csv', names=colnames)\n",
    "titles = data.title.tolist()\n",
    "views = data.views.tolist()\n",
    "descriptions = data.descr.tolist()\n",
    "\n",
    "# Load deswordlists from CSV\n",
    "colnames = ['descriptions', 'words']\n",
    "data = pandas.read_csv('./data/desPlusWords-2.csv', names=colnames)\n",
    "descriptions = data.descriptions.tolist()\n",
    "words = data.words.tolist()\n",
    "\n",
    "\n",
    "# A couple of functions\n",
    "\n",
    "def ourtokens(ourstring):\n",
    "    \n",
    "    stoplist = set(get_stop_words('en'))\n",
    "    finalList = []\n",
    "    \n",
    "    wordList = ourstring.lower().split()\n",
    "    for i in range(len(wordList)):\n",
    "        #wordList[i] = re.sub('[^a-zA-Z\\']', '', wordList[i]).strip(chr(8212)) \n",
    "        #NOTE: the above left spaces and added empty strings\n",
    "        no_punc = wordList[i].strip(string.punctuation) #remove most punctuation\n",
    "        no_emphwhatever = no_punc.strip(chr(8212)) # remove that weirdness\n",
    "        no_num = no_emphwhatever.strip(string.digits) #remove numbers\n",
    "        if (len(no_num) > 0) and (no_num not in stoplist): # Requires stop_words\n",
    "            # First conditional stops empty strings from being added\n",
    "            finalList.append(no_num)            \n",
    "    return finalList\n",
    "\n",
    "def jaccard_similarity(query, document):\n",
    "    intersection = set(query).intersection(set(document))\n",
    "    #print(intersection)\n",
    "    union = set(query).union(set(document))\n",
    "    #print(union)\n",
    "    return len(intersection)/len(union)\n",
    "\n",
    "# Create des_word_lists \n",
    "des_word_lists = []\n",
    "for i in range(len(descriptions)):\n",
    "    # Create list of words for each description\n",
    "    words = ourtokens(descriptions[i])\n",
    "    des_word_lists.append({'descriptions': descriptions[i], 'words': words})\n",
    "    \n",
    "    # Tells you where you are in the rows\n",
    "    if (i % 100) == 0:\n",
    "        print(str(i) + \" rows completed\")\n",
    "        \n",
    "# Create JACCARD MATRIX\n",
    "# From http://stackoverflow.com/questions/568962/how-do-i-create-an-empty-array-matrix-in-numpy\n",
    "Ndes = len(des_word_lists)\n",
    "full_jac_mat = numpy.zeros(shape=(Ndes,Ndes))\n",
    "thresh_JM = numpy.zeros(shape=(Ndes,Ndes))\n",
    "jac_lst = []\n",
    "for i in range(Ndes):\n",
    "    if (i % 100) == 0:\n",
    "        print(str(i) + \" rows completed\")    \n",
    "    # Start the pairwise computations\n",
    "    for j in range((i+1),Ndes):\n",
    "        # Pull the ith and jth document\n",
    "        doc_i = des_word_lists[i]['words']\n",
    "        doc_j = des_word_lists[j]['words']\n",
    "        # Get the Jaccard similarity\n",
    "        jac_ij = jaccard_similarity(doc_i, doc_j)\n",
    "        # Since the Jaccard will be the same between i and j as it will between\n",
    "        # j and i, we set JAC_MAT[i,j] and JAC_MAT[j,i] to be the same value\n",
    "        jac_mat[i,j] = jac_ij\n",
    "        jac_mat[j,i] = jac_ij\n",
    "        \n",
    "        if jac_ij > 0.01:\n",
    "            thresh_JM[i,j] = jac_ij\n",
    "            thresh_JM[j,i] = jac_ij\n",
    "        \n",
    "        # Get all the non-zero Jaccard values\n",
    "        #if jac_ij != 0:\n",
    "            #jac_lst.append(jac_ij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([969863,   9310,    114,     19,      6]),\n",
       " array([ 0.00813008,  0.06737363,  0.12661718,  0.18586073,  0.24510428,\n",
       "         0.30434783]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sort_jac_lst = sorted(jac_lst)\n",
    "np.histogram(jac_lst, bins = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#jac_mat[0:8, 0:10]\n",
    "thresh_JM[0:8, 0:10]\n",
    "numpy.savetxt(\"./testThreshJM.csv\",thresh_JM, fmt = '%1.5f', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.304347826087\n"
     ]
    }
   ],
   "source": [
    "# This block find the maximum for the matrix\n",
    "\n",
    "# Initialize the max to be zero. \n",
    "mat_max = 0\n",
    "\n",
    "# Loop over all the rows\n",
    "for i in range(Ndes):\n",
    "    # Find the maximum for each row\n",
    "    row_max = max(jac_mat[i])\n",
    "    \n",
    "    # Check if the current row's maximum is higher than the current MAT_MAX.\n",
    "    # If the row maximum is bigger, then set MAT_MAX to the row maximum.\n",
    "    if row_max > mat_max:\n",
    "        mat_max = row_max\n",
    "\n",
    "print(mat_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a network from the matrix\n",
    "G = nx.from_numpy_matrix(thresh_JM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Draw the graph\n",
    "\n",
    "pos = nx.spring_layout(G)\n",
    "fig = plt.figure(figsize=(18,18))\n",
    "nx.draw(G, \n",
    "        pos)\n",
    "plt.savefig('./outputs/descriptions-thresh.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save edge list\n",
    "# write_edgelist(G, path, delimiter=',', data=True, encoding='utf-8')\n",
    "nx.write_weighted_edgelist(G, './outputs/desc-net.csv', comments='#', delimiter=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json_graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b190c0fee637>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnetworkx\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mG_in_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_link_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# with open('./outputs/desc_network.json', 'w') as myoutfile:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'json_graph' is not defined"
     ]
    }
   ],
   "source": [
    "# Save JSON graph\n",
    "import json\n",
    "import networkx as nx\n",
    "\n",
    "G_in_json = json_graph.node_link_data(G)\n",
    "\n",
    "# with open('./outputs/desc_network.json', 'w') as myoutfile:\n",
    "#    myoutfile.write(json.dumps(nx.json_graph.node_link_data(G)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prune the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SCANNING\n",
    "# Gdegree = nx.average_degree_connectivity(G)\n",
    "print(Gdegree)\n",
    "\n",
    "# PRUNING                            \n",
    "# remove = [node for node, degree in G.degree().items() if degree <= 4]\n",
    "print(len(remove))\n",
    "# gmt2 = G.remove_nodes_from(remove)\n",
    "# print(len(gmt2.nodes()), len(gmt2.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('./outputs/desc-labels.csv', 'w', newline='\\n') as myfile:\n",
    "    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "    wr.writerow(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example of writing JSON format graph data and using the D3 Javascript library \n",
    "# to produce an HTML/Javascript drawing.\n",
    "#    Copyright (C) 2011-2012 by\n",
    "#    Aric Hagberg <hagberg@lanl.gov>\n",
    "#    Dan Schult <dschult@colgate.edu>\n",
    "#    Pieter Swart <swart@lanl.gov>\n",
    "#    All rights reserved.\n",
    "#    BSD license.\n",
    "\n",
    "__author__ = \"\"\"Aric Hagberg <aric.hagberg@gmail.com>\"\"\"\n",
    "import json\n",
    "import networkx as nx\n",
    "from networkx.readwrite import json_graph\n",
    "import http_server\n",
    "\n",
    "G = nx.barbell_graph(6,3)\n",
    "# this d3 example uses the name attribute for the mouse-hover value,\n",
    "# so add a name to each node\n",
    "for n in G:\n",
    "    G.node[n]['name'] = n\n",
    "# write json formatted data\n",
    "d = json_graph.node_link_data(G) # node-link format to serialize\n",
    "# write json\n",
    "json.dump(d, open('force/force.json','w'))\n",
    "print('Wrote node-link JSON data to force/force.json')\n",
    "# open URL in running web browser\n",
    "http_server.load_url('force/force.html')\n",
    "print('Or copy all files in force/ to webserver and load force/force.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
